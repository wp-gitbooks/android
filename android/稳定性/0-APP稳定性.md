---
number headings: auto, first-level 1, max 6, 1.1
---

# 1 线索
1、平台建设
2、长效治理
3、Crash和ANR问题解决


开篇先定义问题，这篇文章主要是解决哪一类的问题，痛点是什么，之前的方案是怎么设计的，现在的技术方案跟以前相比有什么不同，对其他技术线的同学们来说有什么借鉴价值。这里提醒一句，同学们更喜欢看到方案背后的思考和分析判断，其他相关团队可借鉴复用的部分，深度思考和可借鉴性的价值越大

![image-20210506150743401](http://wupan.dns.army:5000/wupan/Typora-Picgo-Gitee/raw/branch/master/img/20210506150755.png)





![image-20210628150501458](http://wupan.dns.army:5000/wupan/Typora-Picgo-Gitee/raw/branch/master/img/20210628150501.png)


![](http://wupan.dns.army:5000/wupan/Typora-Picgo-Gitee/raw/branch/master/img/20210731223143.png)
# 2 概述


## 2.1 什么是稳定性

- UV Crash率：针对用户使用量的统计，统计一段时间内所有用户发生崩溃的占比
- Crash UV / DAU：评估Crash率的影响范围，结合PV

注意：沿用同一指标

- PV Crash率：评估相关Crash影响的严重程度
- 启动Crash率：影响最严重的Crash，对用户伤害最大，无法通过热修复拯救，需结合客户端容灾
- 增量、存量Crash率：增量Crash是新版本重点，存量Crash是需要持续啃的硬骨头，优先解决增量、持续跟进存量



## 2.2 为什么做稳定性



## 2.3 稳定性分类

### 2.3.1 Crash



### 2.3.2 ANR



# 3 怎么做稳定性

## 3.1 问题类型

### 3.1.1 有稳定复现路径的问题

- 如果一个问题能有稳定的复现路径，解决问题就变得容易很多。
- 这类问题不论Debug信息的多少，都能找根本原因。因为能复现，就可以不断的增加Debug信息。
- 严格来说这类问题不能称为稳定性问题，但依然占据稳定性问题的多数。

### 3.1.2 偶现问题，且Debug信息足够

- 仅使用Android标准的Debug信息就可以定位问题时，都比较容易解决，也不会太复杂。对系统有很好的理解，并且会分析栈信息可能就够用了。但可能需要分析源码来确定根本原因。
- 需要借助厂商附加的Debug信息定位问题时，问题会相对复杂。
- 面对复杂问题时，可能需要仔细分析不同的Debug信息，在它们之间找到关联。尽可能的搜索相关线索，这样才能找到根本原因。
- 有时可能能根据Debug信息定位到代码段，但真正的根本原因还需要分析代码逻辑才能确定。不要轻易下手修改代码，尤其是原生代码。
- 定位到原生代码出问题时，先在网上找一下是否有人给出Patch，相信你不可能是第一个碰到这种问题的人。
- 编写测试代码来验证你的解决方案。

### 3.1.3 偶现问题，且Debug信息不足

- Debug信息不够用时就麻烦了，这也是我认为最难解决的问题。
- 试图寻找复现路径，让问题变为有稳定复现路径的问题。
- 在怀疑点增加Debug信息，等待下一次复现。
- 根据怀疑点分析代码逻辑，试图使用测试代码来复现该问题。
- 根据core文件中的内存镜像来获取更多的有用信息。
- 仔细分析现有的Debug信息，往往一小句话就有很大的惊喜。
- 注意CPU，Memory，IO的状态对系统的影响。
- 怀疑内存问题时可以使用内存检测工具来检查一遍当前系统隐含的内存问题。
- 有时代码检查工具也能规避很多问题，提交前没有检查的最好检查一下。
- 问题很可能不是第一现场，先解决系统之前的错误，后面的错误可能就跟随解决。
- 同样的，在网上搜索是否有类似问题的解决方案。
- 总体来说，这类问题就是尝试各种方法来解决目前无法解决的问题。

### 3.1.4 不能复现的问题

- 此类问题既然无法复现，也就不重要了。
- 如果可以根据Debug信息解决固然很好，不能解决时可以先降低优先级。
- 等待该问题变成偶先问题时，就可以根据上述方法分析了


## 3.2 Crash

- 1、解决线上**常规Crash**
- 2、**系统级Crash**尝试Hook绕过
- 3、**疑难Crash重点突破**或更换方案


### 3.2.1 处理方案

1、根据堆栈及现场信息找答案

- 解决90%问题
- 解决完后需考虑产生Crash深层次的原因

2、找共性：机型、OS、实验开关、资源包，考虑影响范围

3、线下复现、远程调试


### 3.2.2 分析流程

首先，应收集崩溃现场的一些信息，如下：

#### 3.2.2.1 崩溃信息

- 进程名、线程名
- 崩溃堆栈和类型
- 有时候也需要知道主线程的调用栈

#### 3.2.2.2 系统信息

- 系统运行日志

```
/system/etc/event-log-tags
```

- 机型、系统、厂商、CPU、ABI、Linux版本等

注意寻找共性问题

- 设备状态
- 是否root
- 是否是模拟器

#### 3.2.2.3 内存信息

**系统剩余内存**

```
/proc/meminfo
```

当系统可用内存小于MemTotal的10%时，OOM、大量GC、系统频繁自杀拉起等问题非常容易出现

**应用使用内存**

包括Java内存、RSS、PSS

PSS和RSS通过/proc/self/smap计算，可以得到apk、dex、so等更详细的分类统计。

**虚拟内存**

大小：

```
/proc/self/status
```

具体分布情况：

```
/proc/self/maps
```

注意：

对于32位进程，32位CPU，虚拟内存达到3GB就可能会引起内存失败的问题。如果是64位的CPU，虚拟内存一般在3~4GB。如果支持64位进程，虚拟内存就不会成为问题。

#### 3.2.2.4 资源信息

如果应用堆内存和设备内存比较充足，但还出现内存分配失败，则可能跟资源泄漏有关。

**文件句柄fd**

限制数：

```
/proc/self/limits
```

一般单个进程允许打开的最大句柄个数为1024，如果超过800需将所有fd和文件名输出日志进行排查。

**线程数**

大小：

```
/proc/self/status
```

一个线程一般占2MB的虚拟内存，线程数超过400个比较危险，需要将所有tid和线程名输出到日志进行排查。

**JNI**

容易出现引用失效、引用爆表等崩溃。

通过DumpReferenceTables统计JNI的引用表，进一步分析是否出现JNI泄漏等问题。

**补充：dumpReferenceTables的出处**

在dalvik.system.VMDebug类中，是一个native方法，亦是static方法；在JNI中可以这么调用

```
jclass vm_class = env->FindClass("dalvik/system/VMDebug");
jmethodID dump_mid = env->GetStaticMethodID( vm_class, "dumpReferenceTables", "()V" );
env->CallStaticVoidMethod( vm_class, dump_mid );
```

#### 3.2.2.5 应用信息

- 崩溃场景
- 关键操作路径
- 其它跟自身应用相关的自定义信息：运行时间、是否加载补丁、是否全新安装或升级。

接下来进行崩溃分析：

##### 3.2.2.5.1 确定重点

- 确认严重程度
- 优先解决Top崩溃或对业务有重大影响的崩溃：如启动、支付过程的崩溃
- Java崩溃：如果是OOM，需进一步查看日志中的内存信息和资源信息
- Native崩溃：查看signal、code、fault addr以及崩溃时的Java堆栈

常见的崩溃类型有

SIGSEGV：空指针、非法指针等
SIGABRT：ANR、调用abort推出等

如果是ANR，先看主线程堆栈、是否因为锁等待导致，然后看ANR日志中的iowait、CPU、GC、systemserver等信息，确定是I/O问题或CPU竞争问题还是大量GC导致的ANR。

注意：

当从一条崩溃日志中无法看出问题原因时，需要查看相同崩溃点下的更多崩溃日志，或者也可以查看内存信息、资源信息等进行异常排查。

##### 3.2.2.5.2 查找共性

机型、系统、ROM、厂商、ABI这些信息都可以作为共性参考，对于下一步复现问题有明确指引。

##### 3.2.2.5.3 尝试复现

复现之后再增加日志或使用Debugger、GDB进行调试。如不能复现，可以采用一些高级手段，如xlog日志、远程诊断、动态分析等等。

补充：系统崩溃解决方式

- 1、通过共性信息查找可能的原因
- 2、尝试使用其它使用方式规避
- 3、Hook解决


### 3.2.3 个人总结
1、找共性：机型、系统版本等
2、尝试复现
3、尝试修改
4、灰度验证



## 3.3 ANR [[0-ANR]]



# 4 原理

## 4.1 crash

### 4.1.1 crash采集 [[Exception]]   [[崩溃优化]]  [[Crash]]






## 4.2 ANR  [[0-ANR]]




# 5 稳定性平台建设

## 5.1 整体架构

### 5.1.1 采集层

- 错误堆栈
- 设备信息
- 行为日志
- 其它信息

### 5.1.2 处理层

- 数据清洗
- 数据聚合
- 纬度分类
- 趋势对比

### 5.1.3 展示层

- 数据还原
- 纬度信息
- 起始版本
- 其它信息

### 5.1.4 报警层

- 环比：期与上一期进行对比
- 同比：如本月10号与上月10号
- 邮件
- IM
- 电话

### 5.1.5 责任归属

- 设立专项小组轮值
- 自动匹配责任人
- 处理流程全纪录



## 5.2 高可用平台-移动端容灾方案

灾包括：

- 性能异常
- 业务异常

传统流程：

用户反馈、重新打包、渠道更新、不可接受。

### 5.2.1 容灾方案建设

#### 5.2.1.1 功能开关

配置中心，服务端下发配置控制

针对场景：

- 功能新增
- 代码改动

#### 5.2.1.2 统跳中心

- 界面切换通过路由，路由决定是否重定向
- Native Bug不能热修复则跳转到临时H5页面

#### 5.2.1.3 动态化修复

- 热修复能力，可监控、灰度、回滚、清除

**推拉结合、多场景调用保证到达率**



### 5.2.2 天猫安全模式原理

#### 5.2.2.1 如何判断异常退出？

APP启动时记录一个flag值，满足以下条件时，将flag值清空

- APP正常启动10秒
- 用户正常退出应用
- 用户主动从前台切换到后台

如果在启动阶段发生异常，则flag值不会清空，通过flag值就可以判断客户端是否异常退出，每次异常退出，flag值都+1。

#### 5.2.2.2 安全模式的分级执行策略

分为两级安全模式，连续Crash 2次为一级安全模式，连续Crash 2次及以上为二级安全模式。

业务线可以在一级安全模式中注册行为，比如清空缓存数据，再进入该模式时，会使用注册行为尝试修复客户端
如果一级安全模式无法修复APP，则进入二级安全模式将APP恢复到初次安装状态，并将Document、Library、Cache三个根目录清空。

#### 5.2.2.3 热修复执行策略

只要发现配置中需要热修复，APP就会同步阻塞进行热修复,保证修复的及时性

#### 5.2.2.4 灰度方案

灰度时，配置中会包含灰度、正式两份配置及其灰度概率
APP根据特定算法算出自己是否满足灰度条件，则使用灰度配置



# 6 稳定性长效治理

要实现App稳定性的长效治理，我们需要从 **开发阶段 => 测试阶段 => 合码阶段 => 发布阶段 => 运维阶段** 这五个阶段来做针对性地处理。

## 6.1 开发阶段

- 统一编码规范、增强编码功底、技术评审、CodeReview机制
- 架构优化
- 能力收敛
- 统一容错：如在网络库utils中统一对返回信息进行预校验，如不合法就直接不走接下来的流程。

## 6.2 测试阶段

- 功能测试、自动化测试、回归测试、覆盖安装
- 特殊场景、机型等边界测试：如服务端返回异常数据、服务端宕机
- 云测平台：提供更全面的机型进行测试

## 6.3 合码阶段

- 编译检测、静态扫描
- 预编译流程、主流程自动回归

## 6.4 发布阶段

- 多轮灰度
- 分场景、纬度全面覆盖

## 6.5 运维阶段

- 灵敏监控
- 回滚、降级策略
- 热修复、本地容灾方案





# 7 面试题

## 7.1 你们做了哪些稳定性方面的优化？

- Crash专项优化
- 性能稳定性优化
- 业务稳定性优化

根据以上三方面的优化我们搭建了移动端的高可用平台。

## 7.2 性能稳定性是怎么做的？

- 全面的性能优化：启动速度、内存优化、绘制优化
- 线下发现问题、优化为主
- 线上监控为主
- Crash专项优化

## 7.3 业务稳定性如何保障？

- 数据采集 + 报警
- 需要对项目的主流程与核心路径进行埋点监控，
- 同时还需知道每一步发生了多少异常，这样，我们就知道了所有业务流程的转换率以及相应界面的转换率
- 结合大盘，如果转换率低于某个值，进行报警
- 异常监控 + 单点追查
- 兜底策略

## 7.4 如果发送了异常情况，怎么快速止损？

- 功能开关
- 统跳中心
- 动态修复：热修复、资源包更新
- 自主修复：安全模式



## 7.5 业务稳定性如何保障？

- **数据采集 + 报警**
- 需要对项目的**主流程与核心路径进行埋点监控**，
- 同时还**需知道每一步发生了多少异常**，这样，我们就知道了**所有业务流程的转换率以及相应界面的转换率**
- **结合大盘，如果转换率低于某个值，进行报警**
- **异常监控 + 单点追查**
- **兜底策略，如天猫安全模式**



## 7.6 如果发生了异常情况，怎么快速止损？

- **功能开关**
- **统跳中心**
- **动态修复：热修复、资源包更新**
- **自主修复：安全模式**

首先，需要让App具备一些高级的能力，我们对于任何要上线的新功能，要加上一个功能的开关，通过配置中心下发的开关呢，来决定是否要显示新功能的入口。如果有异常情况，可以紧急关闭新功能的入口，那就可以让这个App处于可控的状态了。

然后，我们需要给App设立路由跳转，所有的界面跳转都需要通过路由来分发，如果我们匹配到需要跳转到有bug的这样一个新功能时，那我们就不跳转了，或者是跳转到统一的异常正处理中的界面。如果这两种方式都不可以，那就可以考虑通过热修复的方式来动态修复，目前热修复的方案其实已经比较成熟了，我们完全可以低成本地在我们的项目中添加热修复的能力，当然，如果有些功能是由RN或WeeX来实现就更好了，那就可以通过更新资源包的方式来实现动态更新。而这些如果都不可以的话呢，那就可以考虑自己去给应用加上一个自主修复的能力，如果App启动多次的话，那就可以考虑清空所有的缓存数据，将App重置到安装的状态，到了最严重的等级呢，可以阻塞主线程，此时一定要等App热修复成功之后才允许用户进入。