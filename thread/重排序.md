# 线索


# 概述

## 什么是重排序？
编译器和处理器为了优化程序性能会对指令序列进行重新排序，重排序可能会导致多线程出现内存可见性问题。



![img](https://cdn.jsdelivr.net/gh/wp3355168/Typora-Picgo-Gitee/img/20210721162415.png)





### 编译器重排序

- **编译器优化的重排序**：编译器不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。

JMM对于编译器重排序规则会禁止特定类型的编译器重排序。



### 处理器重排序

- **指令级并行的重排序**：现代处理器采用指令级并行技术（Instruction-Level-Parallelism，ILP）将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应及其指令的执行顺序。
- **内存系统的重排序**：处理器使用缓存和读/写缓冲区，使得加载和存储的操作看起来在乱序执行。

对于处理器重排序，JMM的处理器重排序会要求Java编译器在生成指令序列时，插入特定类型的内存屏障指令，以禁止特定类型的处理器重排序。



## 为什么要指令重排序?
https://blog.csdn.net/q5706503/article/details/84980080

现在的CPU一般采用流水线来执行指令。一个指令的执行被分成：取指、译码、访存、执行、写回、等若干个阶段。然后，多条指令可以同时存在于流水线中，同时被执行。

指令流水线并不是串行的，并不会因为一个耗时很长的指令在“执行”阶段呆很长时间，而导致后续的指令都卡在“执行”之前的阶段上。

重排序的目的是为了性能。
Example:  
理想情况下：  
过程A：cpu0—写入1—> bank0；  
过程B：cpu0—写入2—> bank1；  
如果bank0状态为busy, 则A过程需要等待  
如果进行重排序，则直接可以先执行B过程




## 数据依赖性
如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在**数据依赖性**。

分为下面三种情况：

| 名称   | 示例          | 说明                     |
| ------ | ------------- | ------------------------ |
| 写后读 | a = 1; b = a; | 写一个变量后再读这个位置 |
| 写后写 | a = 1; a = 2; | 写一个变量后再写这个变量 |
| 读后写 | a = b; b = 1; | 读一个变量后再写这个变量 |
上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果将会被改变。
- 所以有数据依赖性的语句不能进行重排序。


### 单线程
#### 单线程中，不会被重排序的逻辑

![img](https://cdn.jsdelivr.net/gh/wp3355168/Typora-Picgo-Gitee/img/20210323203751.png)
由于以上3种情况，任意改变任何一个代码的顺序，结果都会大不相同。所以，对于单线程中这样的逻辑代码，是不会被重排序的。

#### as-if-serial

as-if-serial 语义
: **单线程**下，为了优化可以对操作进行**重排序**。

as-if-serial 语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，runtime 和处理器都必须遵守 as-if-serial 语义。

编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。

Example:
```cpp
double pi  = 3.14;        // Ⓐ
double r   = 1.0;         // Ⓑ  
double area = pi * r * r; // Ⓒ
```

Ⓐ -> Ⓑ -> Ⓒ   按程序顺序的执行结果：area = 3.14
 Ⓑ -> Ⓐ -> Ⓒ   按重排序后的执行结果：area = 3.14

> as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器，写单线程的程序员有一个幻觉：单线程程序是按程序写的顺序来执行的。

### happens-before 规则

https://segmentfault.com/a/1190000011458941

https://www.cnblogs.com/chenssy/p/6393321.html

语义：**如果A先发生于B，那么A所做的所有改变都能被B看到**

遵循的规则

- 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。
- 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。
- volatile变量规则：对一个volatile域的写，happens- before 于任意后续对这个volatile域的读。
- 传递性：如果A happens- before B，且B happens- before C，那么A happens- before C。



以下源自**《深入理解Java虚拟机》**
意味着不遵循以下规则，编译器和处理器将会随意进行重排序。

1. **程序次序规则**（Program Order Rule）：**在一个线程内**，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。
2. **监视器锁规则**（Monitor Lock Rule）：一个unLock操作在时间上先行发生于后面对同一个锁的lock操作。
3. **volatile变量规则**（Volatile Variable Rule）：对一个volatile变量的**写操作在时间上先行发生于后面对这个量的读操作**。
4. **线程启动规则**（Thread Start Rule）：Thread对象的`start()`先行发生于此线程的每一个动作。
5. **线程终止规则**（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测。
6. **线程中断规则**（Thread Interruption Rule）：对线程`interrupt()`方法的调用先行发生于被中断线程的代码检测到中断事件的发生。
7. **对象终结规则**（Finalizer Rule）：一个对象的初始化完成先行发生于它的`finalize()`方法的开始。
8. **传递性**（Transitivity）：A在B之前发生，B在C之前发生，那么A在C之前发生。

#### happens-before关系的定义

1. 如果A happens-before B，A的执行结果对B可见，且A的操作的执行顺序排在B之前，即**时间上先发生不代表是happens-before。**
2. **A happens-before B，A不一定在时间上先发生**。如果两者重排序之后，结果和happens-before的执行结果一致，就ok。

举个例子：

```java
private int value = 0;

public void setValue(int value){
    this.value = value;
}
public int getValue(){
    return value;
}
```

假设此时有两个线程，A线程首先调用`setValue(5)`，然后B线程调用了同一个对象的`getValue`，考虑B返回的value值：

根据`happens-before`的多条规则一一排查：

- 存在于多个线程，不满足程序次序的规则。
- 没有方法使用锁，不满足监视器锁规则。
- 变量没有用volatile关键字修饰，不满足volatile规则。
- 后面很明显，都不满足。

综上所述，最然在时间线上A操作在B操作之前发生，但是它们不满足`happens-before`规则，是无法确定线程B获得的结果是啥，因此，上面的操作不是线程安全的。

如何去修改呢？我们要想办法，让两个操作满足`happens-before`规则。比如：

- 利用**监视器锁规则**，用`synchronized`关键字给`setValue()`和`getValue()`两个方法上一把锁。
- 利用**volatile变量规则**，用`volatile`关键字给value修饰，这样写操作在读之前，就不会修改value值了。





### as-if-serial与happens-before的异同

异：as-if-serial 保证**单线程内**程序的结果不被改变，happens-before 保证**正确同步的多线程**程序的执行结果不被改变。
同：两者都是为了在不改变程序执行结果的前提下，尽可能的**提高程序执行的并行度**。



### 内存屏障 
[[内存屏障]]
[[1-volatile#原理 volatile的实现原理 重排序 内存屏障]]

内存屏障（Memory Barrier，或有时叫做内存栅栏，Memory Fence）是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。Java编译器也会根据内存屏障的规则禁止重排序。

内存屏障可以被分为以下几种类型：

- LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
- StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。
- LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。
- StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。


为了保证final字段的特殊语义，也会在下面的语句加入内存屏障。

> x.finalField = v; StoreStore; sharedRef = x;





## 例子

请先看这样一段代码1：

```java
public class PossibleReordering {
static int x = 0, y = 0;
static int a = 0, b = 0;

public static void main(String[] args) throws InterruptedException {
    Thread one = new Thread(new Runnable() {
        public void run() {
            a = 1;
            x = b;
        }
    });
    
    Thread other = new Thread(new Runnable() {
        public void run() {
            b = 1;
            y = a;
        }
    });
    one.start();other.start();
    one.join();other.join();
    System.out.println(“(” + x + “,” + y + “)”);
}
```

很容易想到这段代码的运行结果可能为(1,0)、(0,1)或(1,1)，因为线程one可以在线程two开始之前就执行完了，也有可能反之，甚至有可能二者的指令是同时或交替执行的。

然而，这段代码的执行结果也可能是(0,0). 因为，在实际运行时，代码指令可能并不是严格按照代码语句顺序执行的。得到(0,0)结果的语句执行过程，如下图所示。值得注意的是，a=1和x=b这两个语句的赋值操作的顺序被颠倒了，或者说，发生了指令“重排序”(reordering)。（事实上，输出了这一结果，并不代表一定发生了指令重排序，内存可见性问题也会导致这样的输出，详见后文）

![重排序图解](https://cdn.jsdelivr.net/gh/wp3355168/Typora-Picgo-Gitee/img/20210721170150.png)

重排序图解



对重排序现象不太了解的开发者可能会对这种现象感到吃惊，但是，笔者开发环境下做的一个小实验证实了这一结果2。

![重排序实验](https://cdn.jsdelivr.net/gh/wp3355168/Typora-Picgo-Gitee/img/20210721170159.png)

重排序实验



实验代码是构造一个循环，反复执行上面的实例代码，直到出现a=0且b=0的输出为止。实验结果说明，循环执行到第13830次时输出了(0,0).

大多数现代微处理器都会采用将指令乱序执行（out-of-order execution，简称OoOE或OOE）的方法，在条件允许的情况下，直接运行当前有能力立即执行的后续指令，避开获取下一条指令所需数据时造成的等待3。通过乱序执行的技术，处理器可以大大提高执行效率。

除了处理器，常见的Java运行时环境的JIT编译器也会做指令重排序操作4，即生成的机器指令与字节码指令顺序不一致。



# 重排序对多线程的影响
考虑重排序对多线程的影响：
如果存在两个线程，A先执行writer()方法，B再执行reader()方法。

```java
class ReorderExample { 
    int a = 0; 
    boolean flag = false; 
    public void writer() { 
        a = 1;              // 1
        flag = true;        // 2 
    }
    Public void reader() { 
        if (flag) {         // 3 
            int i = a * a;  // 4
            …… 
        } 
    } 
}
```

在没有学习重排序相关内容前，我会毫不犹豫地觉得，运行到操作4的时候，已经读取了修改之后的a=1，i也相应的为1。但是，由于重排序的存在，结果也许会出人意料。

![img](https://cdn.jsdelivr.net/gh/wp3355168/Typora-Picgo-Gitee/img/20210721162943.png)

操作1和2，操作3和4都不存在数据依赖，编译器和处理器可以对他们重排序，将会导致多线程的原先语义出现偏差。


# 顺序一致性

## 数据竞争与顺序的一致性

上面示例就存在典型的**数据竞争**：
- 在一个线程中写一个变量。
- 在另一个线程中读这个变量。
- 写和读没有进行同步。

我们应该保证多线程程序的正确同步，保证程序没有数据竞争。

## 顺序一致性内存模型
- 一个线程中的所有操作必须**按照程序**的顺序来执行。
- 所有线程都**只能看到一个单一的操作**执行顺序。
- 每个操作都必须**原子执行**且立刻**对所有线程可见**。

这些机制实际上可以**把所有线程的所有内存读写操作串行化**。

顺序一致性内存模型和JMM对于正确同步的程序，结果是相同的。但对未同步程序，在程序顺序执行顺序上会有不同。
![img](https://cdn.jsdelivr.net/gh/wp3355168/Typora-Picgo-Gitee/img/20210721165609.png)

### JMM处理同步程序

对于正确同步的程序（例如给方法加上synchronized关键字修饰），JMM在不改变程序执行结果的前提下，会在在临界区之内对代码进行重排序，未编译器和处理器的优化提供便利。

### JMM处理非同步程序

对于未同步或未正确同步的多线程程序，JMM提供最小安全性。

**一、什么是最小安全性？**
JMM保证线程读取到的值要么是之前某个线程写入的值，要么是默认值（0，false，Null）。
**二、如何实现最小安全性？**
JMM在堆上分配对象时，首先会对内存空间进行清零，然后才在上面分配对象。因此，在已清零的内存空间分配对象时，域的默认初始化已经完成（0，false，Null）
**三、JMM处理非同步程序的特性？**

1. 不保证单线程内的操作会按程序的顺序执行。
2. 不保证所有线程看到一致的操作执行顺序。
3. 不保证64位的long型和double型的变量的写操作具有原子性。（与处理器总线的工作机制密切相关）

- 对于32位处理器，如果强行要求它对64位数据的写操作具有原子性，会有很大的开销。
- 如果两个写操作被分配到不同的总线事务中，此时64位写操作就不具有原子性。

#### JMM遵循的基本原则
对于**单线程程序和正确同步的多线程程序**，只要不改变程序的执行结果，编译器和处理器无论怎么优化都OK，优化提高效率，何乐而不为。


# 应用
## 单例重排序 [[单例模式的双重检查]]
### 为啥要加双重非空判断呢？双重检查加锁（DCL）

## volatile

## final [[3-final详解]]



# 其他

## Intel 64/IA-32架构下的内存访问重排序

Intel 64和IA-32是我们较常用的硬件环境，相对于其它处理器而言，它们拥有一种较严格的重排序规则。Pentium 4以后的Intel 64或IA-32处理的重排序规则如下。9

在单CPU系统中：

- 读操作不与其它读操作重排序。
- 写操作不与其之前的写操作重排序。
- 写内存操作不与其它写操作重排序，但有以下几种例外
- CLFLUSH的写操作
- 带有non-temporal move指令(MOVNTI, MOVNTQ, MOVNTDQ, MOVNTPS, and MOVNTPD)的streaming写入。
- 字符串操作
- 读操作可能会与其之前的写不同位置的写操作重排序，但不与其之前的写相同位置的写操作重排序。
- 读和写操作不与I/O指令，带锁的指令或序列化指令重排序。
- 读操作不能重排序到LFENCE和MFENCE之前。
- 写操作不能重排序到LFENCE、SFENCE和MFENCE之前。
- LFENCE不能重排序到读操作之前。
- SFENCE不能重排序到写之前。
- MFENCE不能重排序到读或写操作之前。

在多处理器系统中：

- 各自处理器内部遵循单处理器的重排序规则。
- 单处理器的写操作对所有处理器可见是同时的。
- 各自处理器的写操作不会重排序。
- 内存重排序遵守因果性(causality)（内存重排序遵守传递可见性）。
- 任何写操作对于执行这些写操作的处理器之外的处理器来看都是一致的。
- 带锁指令是顺序执行的。

值得注意的是，对于Java编译器而言，Intel 64/IA-32架构下处理器不需要LoadLoad、LoadStore、StoreStore屏障，因为不会发生需要这三种屏障的重排序。

## 一例Intel 64/IA-32架构下的代码性能优化

现在有这样一个场景，一个容器可以放一个东西，容器支持create方法来创建一个新的东西并放到容器里，支持get方法取到这个容器里的东西。我们可以较容易地写出下面的代码：

```java
public class Container {
    public static class SomeThing {
        private int status;

        public SomeThing() {
            status = 1;
        }

        public int getStatus() {
            return status;
        }
    }

    private SomeThing object;

    public void create() {
        object = new SomeThing();
    }

    public SomeThing get() {
        while (object == null) {
            Thread.yield(); //不加这句话可能会在此出现无限循环
        }
        return object;
    }
}
```

在单线程场景下，这段代码执行起来是没有问题的。但是在多线程并发场景下，由不同的线程create和get东西，这段代码是有问题的。问题的原因与普通的双重检查锁定单例模式(Double Checked Locking,DCL)10类似，即SomeThing的构建与将指向构建中的SomeThing引用赋值到object变量这两者可能会发生重排序。导致get中返回一个正被构建中的不完整的SomeThing对象实例。为了解决这一问题，通常的办法是使用volatile修饰object字段。这种方法避免了重排序，保证了内存可见性，摒弃比使用同步块导致的性能损失更小。但是，假如使用场景对object的内存可见性并不敏感的话（不要求一个线程写入了object，object的新值立即对下一个读取的线程可见），在Intel 64/IA-32环境下，有更好的解决方案。

根据上一章的内容，我们知道Intel 64/IA-32下写操作之间不会发生重排序，即在处理器中，构建SomeThing对象与赋值到object这两个操作之间的顺序性是可以保证的。这样看起来，仅仅使用volatile来避免重排序是多此一举的。但是，Java编译器却可能生成重排序后的指令。但令人高兴的是，Oracle的JDK中提供了Unsafe. putOrderedObject，Unsafe. putOrderedInt，Unsafe. putOrderedLong这三个方法，JDK会在执行这三个方法时插入StoreStore内存屏障，避免发生写操作重排序。而在Intel 64/IA-32架构下，StoreStore屏障并不需要，Java编译器会将StoreStore屏障去除。比起写入volatile变量之后执行StoreLoad屏障的巨大开销，采用这种方法除了避免重排序而带来的性能损失以外，不会带来其它的性能开销。

我们将做一个小实验来比较二者的性能差异。一种是使用volatile修饰object成员变量。

```java
public class Container {
    public static class SomeThing {
        private int status;

        public SomeThing() {
            status = 1;
        }

        public int getStatus() {
            return status;
        }
    }

    private volatile  SomeThing object;

    public void create() {
        object = new SomeThing();
    }

    public SomeThing get() {
        while (object == null) {
            Thread.yield(); //不加这句话可能会在此出现无限循环
        }
        return object;
    }
}
```

一种是利用Unsafe. putOrderedObject在避免在适当的位置发生重排序。

```java
public class Container {
    public static class SomeThing {
        private int status;

        public SomeThing() {
            status = 1;
        }

        public int getStatus() {
            return status;
        }
    }

    private SomeThing object;

    private Object value;
    private static final Unsafe unsafe = getUnsafe();
    private static final long valueOffset;
    static {
        try {
            valueOffset = unsafe.objectFieldOffset(Container.class.getDeclaredField("value"));
        } catch (Exception ex) { throw new Error(ex); }
    }

    public void create() {
        SomeThing temp = new SomeThing();
        unsafe.putOrderedObject(this, valueOffset, null);	//将value赋null值只是一项无用操作，实际利用的是这条语句的内存屏障
        object = temp;
    }

    public SomeThing get() {
        while (object == null) {
            Thread.yield();
        }
        return object;
    }


    public static Unsafe getUnsafe() {
        try {
            Field f = Unsafe.class.getDeclaredField("theUnsafe");
            f.setAccessible(true);
            return (Unsafe)f.get(null);
        } catch (Exception e) {
        }
        return null;
    }
}
```

由于直接调用Unsafe.getUnsafe()需要配置JRE获取较高权限，我们利用反射获取Unsafe中的theUnsafe来取得Unsafe的可用实例。
unsafe.putOrderedObject(this, valueOffset, null) 这句仅仅是为了借用这句话功能的防止写重排序，除此之外无其它作用。

利用下面的代码分别测试两种方案的实际运行时间。在运行时开启-server和 -XX:CompileThreshold=1以模拟生产环境下长时间运行后的JIT优化效果。

```java
public static void main(String[] args) throws InterruptedException {
    final int THREADS_COUNT = 20;
    final int LOOP_COUNT = 100000;

    long sum = 0;
    long min = Integer.MAX_VALUE;
    long max = 0;
    for(int n = 0;n <= 100;n++) {
        final Container basket = new Container();
        List<Thread> putThreads = new ArrayList<Thread>();
        List<Thread> takeThreads = new ArrayList<Thread>();
        for (int i = 0; i < THREADS_COUNT; i++) {
            putThreads.add(new Thread() {
                @Override
                public void run() {
                    for (int j = 0; j < LOOP_COUNT; j++) {
                        basket.create();
                    }
                }
            });
            takeThreads.add(new Thread() {
                @Override
                public void run() {
                    for (int j = 0; j < LOOP_COUNT; j++) {
                        basket.get().getStatus();
                    }
                }
            });
        }
        long start = System.nanoTime();
        for (int i = 0; i < THREADS_COUNT; i++) {
            takeThreads.get(i).start();
            putThreads.get(i).start();
        }
        for (int i = 0; i < THREADS_COUNT; i++) {
            takeThreads.get(i).join();
            putThreads.get(i).join();
        }
        long end = System.nanoTime();
        long period = end - start;
        if(n == 0) {
            continue;	//由于JIT的编译，第一次执行需要更多时间，将此时间不计入统计
        }
        sum += (period);
        System.out.println(period);
        if(period < min) {
            min = period;
        }
        if(period > max) {
            max = period;
        }
    }
    System.out.println("Average : " + sum / 100);
    System.out.println("Max : " + max);
    System.out.println("Min : " + min);
}
```

在笔者的计算机上运行测试，采用volatile方案的运行结果如下：

```
Average : 62535770
Max : 82515000
Min : 45161000
```

采用unsafe.putOrderedObject方案的运行结果如下：

```
Average : 50746230
Max : 68999000
Min : 38038000
```

从结果看出，unsafe.putOrderedObject方案比volatile方案平均耗时减少18.9%，最大耗时减少16.4%，最小耗时减少15.8%.另外，即使在其它会发生写写重排序的处理器中，由于StoreStore屏障的性能损耗小于StoreLoad屏障，采用这一方法也是一种可行的方案。但值得再次注意的是，这一方案不是对volatile语义的等价替换，而是在特定场景下做的特殊优化，它仅避免了写写重排序，但不保证内存可见性。



# 参考

https://tech.meituan.com/2014/09/23/java-memory-reordering.html

https://www.jianshu.com/p/b4d4506d3585

https://www.cnblogs.com/summerday152/p/12296420.html

https://juejin.cn/post/6844903585784791048#heading-7





1. 样例选自《Java并发编程实践》章节16.1
2. 实验代码见附1
3. http://en.wikipedia.org/wiki/Out-of-order_execution
4. Oracle Java Hotspot https://wikis.oracle.com/display/HotSpotInternals/PerformanceTacticIndex IBM JVM http://publib.boulder.ibm.com/infocenter/javasdk/v1r4m2/index.jsp?topic=%2Fcom.ibm.java.doc.diagnostics.142j9%2Fhtml%2Fhowjitopt.html
5. Java语言规范中对“动作”这个词有一个明确而具体的定义，详见http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.2。
6. https://community.oracle.com/thread/1544959
7. http://www.cs.umd.edu/~pugh/java/memoryModel/jsr133.pdf
8. 参见《Java并发编程实践》章节16.1
9. Intel® 64 and IA-32 Architectures Software Developer’s Manual Volume 3 (3A, 3B & 3C): System Programming Guide章节8.2
10. http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html



参考资料：
《Java并发编程的艺术》方腾飞
《深入理解Java虚拟机》周志明